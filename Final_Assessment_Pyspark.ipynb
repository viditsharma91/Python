{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfa3a2b",
   "metadata": {},
   "source": [
    "<h1><center>FINAL ASSESSMENT</center></h1>          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d92178",
   "metadata": {},
   "source": [
    "## COURSE\tNAME:   THE BIG DATA TOOLKIT\n",
    "## COURSE\tCODE:\tMADSC103\n",
    "## Name:                      Vidit Sharma \n",
    "## Student Code:        21041911"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b2e548",
   "metadata": {},
   "source": [
    "#### 1) Start a simple Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a39fa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8dcc3e",
   "metadata": {},
   "source": [
    "#### 2) Load the Walmart Stock csv file, have Spark to infer the data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d15c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (StructField, StringType,\n",
    "                               IntegerType, StructType)\n",
    "\n",
    "data_schema = [StructField('Open', StringType(), True),\n",
    "               StructField('High', StringType(), True),\n",
    "               StructField('Low', StringType(), True),\n",
    "               StructField('Close', StringType(), True),\n",
    "               StructField('Volume', StringType(), True),\n",
    "               StructField('Adj Close', StringType(), True)\n",
    "              ]\n",
    "\n",
    "final_struc = StructType(fields=data_schema)\n",
    "\n",
    "df = spark.read.csv('walmart_stock.csv', inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc03336",
   "metadata": {},
   "source": [
    "#### 3) How does the schema looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e62c0953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aeae6f",
   "metadata": {},
   "source": [
    "##### 4)Print out the first 5 columns (hint: use a for loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cffaf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Date=datetime.datetime(2012, 1, 3, 0, 0), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996) \n",
      "\n",
      "Row(Date=datetime.datetime(2012, 1, 4, 0, 0), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475) \n",
      "\n",
      "Row(Date=datetime.datetime(2012, 1, 5, 0, 0), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539) \n",
      "\n",
      "Row(Date=datetime.datetime(2012, 1, 6, 0, 0), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922) \n",
      "\n",
      "Row(Date=datetime.datetime(2012, 1, 9, 0, 0), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in df.head(5):\n",
    "    print(line, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d623a0",
   "metadata": {},
   "source": [
    "#### 5) Format the qualitative variables in your dataframe to show just two decimal places. (Open, High, Low, Close, Volume). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6895ef",
   "metadata": {},
   "source": [
    "Formatting all columns of the data frame to 2 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce9a687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+-----+-----+--------+---------+\n",
      "|               Date| Open| High|  Low|Close|  Volume|Adj Close|\n",
      "+-------------------+-----+-----+-----+-----+--------+---------+\n",
      "|2012-01-03 00:00:00|59.97|61.06|59.87|60.33|12668800|    52.62|\n",
      "|2012-01-04 00:00:00|60.21|60.35|59.47|59.71| 9593300|    52.08|\n",
      "|2012-01-05 00:00:00|59.35|59.62|58.37|59.42|12768200|    51.83|\n",
      "|2012-01-06 00:00:00|59.42|59.45|58.87| 59.0| 8069400|    51.46|\n",
      "|2012-01-09 00:00:00|59.03|59.55|58.92|59.18| 6679300|    51.62|\n",
      "|2012-01-10 00:00:00|59.43|59.71|58.98|59.04| 6907300|    51.49|\n",
      "|2012-01-11 00:00:00|59.06|59.53|59.04| 59.4| 6365600|    51.81|\n",
      "|2012-01-12 00:00:00|59.79| 60.0| 59.4| 59.5| 7236400|     51.9|\n",
      "|2012-01-13 00:00:00|59.18|59.61|59.01|59.54| 7729300|    51.93|\n",
      "|2012-01-17 00:00:00|59.87|60.11|59.52|59.85| 8500000|     52.2|\n",
      "|2012-01-18 00:00:00|59.79|60.03|59.65|60.01| 5911400|    52.34|\n",
      "|2012-01-19 00:00:00|59.93|60.73|59.75|60.61| 9234600|    52.86|\n",
      "|2012-01-20 00:00:00|60.75|61.25|60.67|61.01|10378800|    53.21|\n",
      "|2012-01-23 00:00:00|60.81|60.98|60.51|60.91| 7134100|    53.13|\n",
      "|2012-01-24 00:00:00|60.75| 62.0|60.75|61.39| 7362800|    53.54|\n",
      "|2012-01-25 00:00:00|61.18|61.61|61.04|61.47| 5915800|    53.61|\n",
      "|2012-01-26 00:00:00| 61.8|61.84|60.77|60.97| 7436200|    53.18|\n",
      "|2012-01-27 00:00:00|60.86|61.12|60.54|60.71| 6287300|    52.95|\n",
      "|2012-01-30 00:00:00|60.47|61.32|60.35| 61.3| 7636900|    53.47|\n",
      "|2012-01-31 00:00:00|61.53|61.57|60.58|61.36| 9761500|    53.52|\n",
      "+-------------------+-----+-----+-----+-----+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "for c_name, c_type in df.dtypes:\n",
    "    if c_type in ('double', 'float'):\n",
    "        df = df.withColumn(c_name, round(c_name, 2))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1001b61a",
   "metadata": {},
   "source": [
    "Displaying the summary (count, mean, SD, min and max) of the data frame columns using .describe() and formatting to 2 decimal places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa83300b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+-------------+\n",
      "|summary|    Open|    High|     Low|   Close|       Volume|\n",
      "+-------+--------+--------+--------+--------+-------------+\n",
      "|  count|1,258.00|1,258.00|1,258.00|1,258.00|     1,258.00|\n",
      "|   mean|   72.36|   72.84|   71.92|   72.39| 8,222,093.50|\n",
      "| stddev|    6.77|    6.77|    6.74|    6.76| 4,519,781.00|\n",
      "|    min|   56.39|   57.06|   56.30|   56.42| 2,094,900.00|\n",
      "|    max|   90.80|   90.97|   89.25|   90.47|80,898,096.00|\n",
      "+-------+--------+--------+--------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number\n",
    "\n",
    "summary = df.describe()\n",
    "summary.select(summary['summary'],\n",
    "              format_number(summary['Open'].cast('float'),2).alias('Open'),\n",
    "              format_number(summary['High'].cast('float'),2).alias('High'),\n",
    "              format_number(summary['Low'].cast('float'),2).alias('Low'),\n",
    "              format_number(summary['Close'].cast('float'),2).alias('Close'),\n",
    "              format_number(summary['Volume'].cast('float'),2).alias('Volume')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cb1c4d",
   "metadata": {},
   "source": [
    "#### 6) Create a new dataframe with a column called HR ratio that is the ratio of the High Price versus volume of stock traded for a day. Change the format of HR ratio to show two decimal places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c761a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            HR_Ratio|\n",
      "+--------------------+\n",
      "|4.819714574387472E-6|\n",
      "|6.290848821573389...|\n",
      "|4.669413073103491E-6|\n",
      "|7.367338339901356E-6|\n",
      "|8.915604928660188E-6|\n",
      "|8.644477581688938E-6|\n",
      "| 9.35182857861003E-6|\n",
      "| 8.29141562102703E-6|\n",
      "|7.712211972623653E-6|\n",
      "|7.071764705882352...|\n",
      "|1.015495483303447...|\n",
      "|6.576354146362592...|\n",
      "| 5.90145296180676E-6|\n",
      "|8.547679455011844E-6|\n",
      "|8.420709512685392E-6|\n",
      "|1.041448324825044...|\n",
      "|8.316075414862431E-6|\n",
      "|9.721183974042911E-6|\n",
      "|8.029436027707578E-6|\n",
      "|6.307432259386365E-6|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hr = df.withColumn('HR_Ratio', df['High']/df['Volume']).select(['HR_Ratio'])\n",
    "df_hr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe0949",
   "metadata": {},
   "source": [
    "Round off HR_Ratio to 2 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60200662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|HR_Ratio|\n",
      "+--------+\n",
      "|0.00    |\n",
      "|0.00    |\n",
      "|0.00    |\n",
      "|0.00    |\n",
      "|0.00    |\n",
      "|0.00    |\n",
      "|0.00    |\n",
      "|0.00    |\n",
      "|0.00    |\n",
      "|0.00    |\n",
      "+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_hr.withColumn(\"HR_Ratio\", format_number(col(\"HR_Ratio\"),2)).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18b970a",
   "metadata": {},
   "source": [
    "In the above output of rounding off we see that the result is 0.00 for all the values because the real number for 4.819714653321546E-6 is 0.000004819714653321546. \n",
    "However to see the number clearly we can round off to more than 5 decimal places as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faaa95c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|HR_Ratio  |\n",
      "+----------+\n",
      "|0.00000482|\n",
      "|0.00000629|\n",
      "|0.00000467|\n",
      "|0.00000737|\n",
      "|0.00000892|\n",
      "|0.00000864|\n",
      "|0.00000935|\n",
      "|0.00000829|\n",
      "|0.00000771|\n",
      "|0.00000707|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hr.withColumn(\"HR_Ratio\", format_number(col(\"HR_Ratio\"),8)).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fccb923",
   "metadata": {},
   "source": [
    "#### 7) What is the mean of the Close column? Change the format to show two decimal places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52f52801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Close)|\n",
      "+-----------------+\n",
      "|72.38844992050863|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "\n",
    "mean = df.select(mean('Close')).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f09338",
   "metadata": {},
   "source": [
    "#### 8) What is the max and min of the Volume column? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e0262fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|   80898100|    2094900|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "df.select(max('Volume'),min('Volume')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1ecb18",
   "metadata": {},
   "source": [
    "#### 9) How many days was the Close lower than 60 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08714344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Close'] < 60).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a33bdf",
   "metadata": {},
   "source": [
    "#### 10) What percentage of the time was the High greater than 80 dollars? In other words, (Number of Days High >80) / (Total days in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b370b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.141494435612083"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter('High > 80').count() * 100/df.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
